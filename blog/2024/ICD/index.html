<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Instance-Conditional Knowledge Distillation for Object Detection (ICD) | SeongHak KIM</title> <meta name="author" content="SeongHak KIM"> <meta name="description" content="Review of " instance-conditional knowledge distillation for object detection by z. kang et al. as presented at neurips> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%98%98%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://seonghak35.github.io/blog/2024/ICD/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">SeongHak </span>KIM</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">SeongHak</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/leaderboard/">Leaderboard</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Instance-Conditional Knowledge Distillation for Object Detection (ICD)</h1> <p class="post-meta">January 18, 2024</p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/model-compression"> <i class="fa-solid fa-hashtag fa-sm"></i> model_compression</a>     ·   <a href="/blog/category/ai"> <i class="fa-solid fa-tag fa-sm"></i> AI</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="introduction">Introduction</h2> <p>High performance의 Deep Learning Networks의 성능을 얻기 위해서는, 불가피하게 많은 양의 parameters를 수반하게 되며, 이는 high computational cost와 memory를 필요하게 만든다. 따라서, Resource-limited devices에서 object detection과 같은 실용적인 application을 사용하기 위해, network pruning, quantization, mobile architecture design, 그리고 knowledge distillation (KD)의 방법들이 등장했다. 그 중에서 KD는 추가적인 inference time 부담과 수정없이 network의 효율성과 성능을 개선시킬 수 있기 때문에 많이 적용되고 있다.</p> <p>지금까지의 많은 KD들은 image classification에 집중되어 연구가 진행되었고, 다음의 이유로 인해 이를 object detection에 그대로 적용하기는 힘들다고 알려져 있다.</p> <ol> <li>물체의 localization이 고려되지 않았다.</li> <li>서로 다른 위치에 분포되어 있는 여러개의 물체들이 하나의 이미지에 나타나 있다 (서로 다른 위치로부터의 representation은 서로 다른 contribution를 가지므로 distillation를 어렵게 만든다, i.e., imbalance issue).</li> </ol> <p>이를 해결하기 위해 기존의 논문들은 다음과 같은 방법을 사용했다.</p> <ol> <li>classification과 localization에 대한 정보를 함께 가진 intermediate representations를 distillation한다.</li> <li>imbalance 문제를 해결하기 위해 different feature selection 방법을 사용한다. <ul> <li>Proposal-based: RPN에 의해 예측된 proposal regions이나 detector를 활용</li> <li>Rule-based: pre-design된 rule로 선별된 regions을 활용 <br> ; 하지만, 이러한 방법들은 유익한 informative regions를 무시한다.</li> <li>Attention-based: discriminative area에 대한 hints를 제공하지만, detection을 위한 activation과 knowledge사이의 관계가 clear하지 않다.</li> </ul> </li> </ol> <p>이에 따라, 본 논문에서는 Instance-Conditional knowledge Distillation (ICD)를 제안함으로써, knowledge를 feature selection과 연결하는 explicit solution을 제공한다. 이를 위해,</p> <ul> <li>transformer decoder를 통해 instance-aware attention으로 지식과 각 instance 사이의 correlation을 측정함으로써, 서로 다른 instance와 관련된 지식을 찾도록 하는 conditional decoding module를 설계한다.</li> <li>여기서, 사람이 관찰한 instance를 query로 사용하고, teacher’s representation (decomposed into key and value)과의 사이를 scaled-product attention을 통해 correlation을 계산한다.</li> </ul> <p>결과적으로, decoder를 통해 구분된 features들을 distillation하고, instance-aware attention을 통해 weighted된다.</p> <h2 id="related-works">Related Works</h2> <h3 id="object-detection">Object Detection</h3> <p>Object detection에서의 detector은 크게 two-stage 또는 one-stage detectors로 구분할 수 있다. Two-stage는 일반적으로 Region Proposal Network (RPN)을 사용하여, 초기의 대략적인 prediction을 얻고, detection heads를 통해 이를 refine하는 과정을 거친다. 대표적으로 Faster F-CNN이 있다. 반면, one-stage detectors의 경우, feature map에 대해 바로 예측을 하기 때문에 더 빠르다고 알려져 있다. 대표적으로 RetinaNet이 있다.</p> <h2 id="method">Method</h2> <h3 id="overview">Overview</h3> <p>일반적으로, detection의 유용한 지식들은 intermediate features에 불균등하게 분포되어 있다. 이를 개선하기 위해 본 논문은, 다음과 같은 식을 통해, instance-conditional knowledge를 전달한다.</p> \[\mathcal{L}_=\sum_{i=1}^N \mathcal{L}_d\left(\kappa_i^{\mathcal{S}}, \kappa_i^{\mathcal{T}}\right)\] <p>여기서, \(\kappa_i^\mathcal{T}=\mathcal{G}(\mathcal{T},\mathrm{y}_i)\)는 condition \((\mathrm{y}_i)\)과 teacher representations \((\mathcal{T})\)에 대한 knowledge를 의미하고, \(\mathcal{G}\)는 instance-conditional decoding module를 나타내며, 이는 auxiliary loss를 통해 최적화된다.</p> <h3 id="instance-conditional-knowledge-kappa_i">Instance-Conditional Knowledge \((\kappa_i)\)</h3> <p>Instance-conditional decoding module \((\mathcal{G})\)을 통해 instance condition이 주어졌을 때, unconditional knowledge \((\mathcal{T})\)로부터 instance-conditional knowledge \((\kappa^\mathcal{T}_i)\)를 구할 수 있다.</p> <ol> <li>Unconditional knowledge \((\mathcal{T})\)는 teacher detector로부터 사용가능한 모든 정보를 의미한다. Multi-scale representations로 나타내면 \(\mathcal{T}=\left[X_p\in\mathbb{R}^{D \times H_p \times W_p}\right]_{p\in\mathcal{P}}\)가 되며, 여기서 \(\mathcal{P}\)는 spatial resolutions, \(D\)는 channel dimension을 의미한다. Spatial dimension를 따라 서로 다른 scales의 representations을 concatenation하게 되면 \(A^\mathcal{T}\in\mathbb{R}^{L\times D}\)가 되며, 여기서 \(L=\sum_{p\in\mathcal{P}}H_p\times W_p\)는 scale를 걸쳐서 모든 pixels의 수를 합한 것이다.</li> <li>Instance condition은 \(\mathcal{Y}=(\mathrm{y}_i)^N_{i=1}\)로 나타내며, 여기서 \(N\)는 object의 수를, \(\mathrm{y}_i=(c_i,\mathbf{b}_i)\)는 \(i\)-th instance에 대한 annotation를 의미한다. 즉, category \(c_i\)와 box location \(\mathbf{b}_i=(x_i,y_i,w_i,h_i)\)이다.</li> </ol> <p>각 instance에 대해 학습가능한 embedding를 만들기 위해, annotation을 hidden space상에서의 query feature vector \((\mathbf{q}_i)\)로 mapping하게 되며, 이때 아래의 식처럼, 원하는 knowledge를 얻기위해 condition을 지정하게 된다.</p> \[\mathbf{q}_i=\mathcal{F}_q(\mathcal{E}(\mathrm{y}_i)),\quad\mathbf{q}_i\in\mathbb{R}^D\] <p>여기서 \(\mathcal{E}(\cdot)\)는 instance encoding function을, \(\mathcal{F}_q\)는 MLP를 나타낸다.</p> <p>\(\mathbf{q}_i\)가 주어졌을 때, \(\mathcal{T}\)로부터의 knowledge를 찾기 위해서 correlation을 측정하는데, 이는 dot-product attention을 사용하여 얻을 수 있으며, 각 head \(j\)는 3개의 선형 layers \((\mathcal{F}^k_j,\mathcal{F}^k_q,\mathcal{F}^k_v)\)에 상응한다.</p> <p>아래의 식과 같이, key feature \((\mathrm{K}^\mathcal{T}_j)\)는 teacher의 representation \((\mathrm{A}^\mathcal{T})\)를 positional embeddings \((\mathrm{P}\in\mathbb{R}^{L\times d})\)과 projection하여 계산할 수 있다.</p> \[\mathrm{K}_j^{\mathcal{T}}=\mathcal{F}_j^k\left(\mathrm{A}^{\mathcal{T}}+\mathcal{F}_{p e}(\mathrm{P})\right), \mathrm{K}_j^{\mathcal{T}} \in \mathbb{R}^{L \times d}\] <p>여기서, \(\mathcal{F}_{p e}\)는 position embeddings를 통한 선형 projection을 의미한다. 유사하게, value feature와 query는 아래와 같다.</p> \[\mathrm{V}_j^{\mathcal{T}}=\mathcal{F}_j^v\left(\mathrm{A}^{\mathcal{T}}\right), \quad \mathrm{V}_j^{\mathcal{T}} \in \mathbb{R}^{L \times d}\] \[\mathbf{q}_{i j}=\mathcal{F}_j^q\left(\mathbf{q}_i\right), \quad \mathbf{q}_{i j} \in \mathbb{R}^d\] <p>마지막으로, \(j\)-th head에 의한 \(i\)-th instance의 instance-aware attention mask \(\mathbf{m}_{ij}\)는 \(\mathrm{K}_j^\mathcal{T}\)와 \(\mathbf{q}_{ij}\)사이의 normalized dot-product를 통해 구할 수 있다.</p> \[\mathbf{m}_{i j}=\operatorname{softmax}\left(\frac{\mathrm{K}_j^{\mathcal{T}} \mathbf{q}_{i j}}{\sqrt{d}}\right), \mathbf{m}_{i j} \in \mathbb{R}^L\] <p>최종적으로, querying along the key feature \((\mathbf{m}_{i j})\)와 value features \((\mathrm{V}_j^{\mathcal{T}})\)는 representations과 instances간의 correlation을 의미하기 때문에 instance-condition knowledge는 \(\kappa_i^{\mathcal{T}}=\left\{\left(\mathbf{m}_{i j}, \mathrm{V}_j^{\mathcal{T}}\right)\right\}_{j=1}^M\)가 되며, 이는 \(i\)-th instance에 상응하는 knowledge를 encoding한다.</p> <h3 id="auxiliary-task">Auxiliary Task</h3> <p>앞서 설명한 decoding module \((\mathcal{G})\)을 최적화하기 위해 auxiliary tasks를 활용한다. 우선, 함수 \(\mathcal{F}_{agg}\)로 instance-conditional knowledge를 통합 (instance-level aggregated information \(\mathbf{g}_i^{\mathcal{T}}\))하여 객체를 식별하고 위치를 파악할 수 있다.</p> \[\mathbf{g}_i^{\mathcal{T}}=\mathcal{F}_{a g g}\left(\kappa_i^{\mathcal{T}}, \mathbf{q}_i\right), \mathbf{g}_i^{\mathcal{T}} \in \mathbb{R}^D\] <p>Instance-level aggregated information \(\mathbf{g}_i^{\mathcal{T}}\)이 충분한 instance 단서를 유지하도록 하기위해, 아래와 같이 instance-sensitive tasks를 사용하여 최적화한다.</p> \[\mathcal{L}_{a u x}=\mathcal{L}_{i n s}\left(\mathbf{g}_i^{\mathcal{T}}, \mathcal{H}\left(\mathrm{y}_i\right)\right)\] <p>여기서 \(\mathcal{H}\)는 instance information을 targets으로 encode한다.</p> <p>다만, 위 식에서 \(i\)-th instance annotation에 해당하는 \(\mathrm{y}_i\)를 \(\mathbf{g}_i^{\mathcal{T}}\)와 \(\mathcal{H}\left(\mathrm{y}_i\right)\)를 통해서 구할수 있기 때문에 위 식을 바로 사용하면 trivial solution이 된다. 이는 결과적으로, teacher representation \(\mathcal{T}\)를 무시하고 parameters를 학습하게 될 가능성이 있다는 것을 의미한다. 이를 해결하기 위해, encoding function \(\mathcal{E}(\cdot)\)에 대한 정보를 drop하여 aggregation function \(\mathcal{F}_{agg}\)이 \(\mathcal{T}\)로부터 hint를 얻도록한다.</p> <p>이러한 information dropping은 instance condition에 대한 정확한 annotation을 불확실한 것으로 교체하는 것을 의미하는데, bounding box annotations의 경우에는, 아래의 식과 같이 rough box center \(\left(x_i', y_i'\right)\)와 rough scales indicators \([\log_2(w_i)], [\log_2(h_2)]\)를 활용하여 얻을 수 있다.</p> \[\left\{\begin{array}{l} x_i^{\prime}=x_i+\phi_x w_i, \\ y_i^{\prime}=y_i+\phi_y h_i, \end{array}\right.\] <p>여기서, \(\left(w_i,w_i\right)\)는 bounding box의 width와 height를 나타내며, \(\phi_x, \phi_y\)는 uniform distribution \(\Phi \sim U[-3, 3]\)에서 샘플된 값을 의미한다. 결과적으로 coarse information을 얻어 \(\mathcal{E}\)를 통해 instance encoding을 얻을 수 있다.</p> <p>Aggregated representation \(\mathbf{g}_i^\mathcal{T}\)는 auxiliary task로 최적화되는 데, 이를 위해 \(\mathcal{F}_{obj}\)와 \(\mathcal{F}_{reg}\)를 각각 도입하여, identification과 localization results를 예측한다. 아래의 식과 같이 real-fake identification을 최적화하기 위해 binary cross entropy loss (BCE)를, regression을 최적화하기 위해 \(L1\) loss를 적용한다.</p> \[\mathcal{L}_{aux}=\mathcal{L}_{BCE}\left(\mathcal{F}_{obj}\left(\mathbf{g}_i^\mathcal{T}\right),\delta_{obj}(\mathrm{y}_i)\right)+\mathcal{L}_{1}\left(\mathcal{F}_{reg}\left(\mathbf{g}_i^\mathcal{T}\right),\delta_{reg}(\mathrm{y}_i)\right)\] <p>여기서, \(\delta_{obj}(\cdot)\)은 indicator로서, \(\mathrm{y}_i\)가 real이면 1을 fake이면 0을 뱉어낸다.</p> <h3 id="instance-conditional-distillation">Instance-Conditional Distillation</h3> <p>Conditional knowledge distillation를 하기 위해, student representations의 projected value features \(\mathrm{V}_j^\mathcal{S}\in\mathbb{R}^{L\times d}\)를 얻고, feature와 각 instance 사이의 correlations을 측정하는 instance-aware attention mask \(\mathbf{m}_{ij}\)를 사용함으로써, 아래와 같이 distillation loss를 설계할 수 있다.</p> \[\mathcal{L}_{distill} = \frac{1}{MN_r}\sum^{M}_{j=1}\sum^{N}_{i=1}\delta_{obj}(\mathrm{y}_i)\cdot\left&lt;\mathbf{m}_{ij},\mathcal{L}_{MSE}\left(\mathrm{V}^\mathcal{S}_j,\mathrm{V}^\mathcal{T}_j\right)\right&gt;\] <p>여기서, \(N_r=\sum^{N}_{i=1}\delta_{obj}(\mathrm{y}_i), (N_r\le N)\)는 real instance의 수를 나타내고, \(\mathcal{L}_{MSE}\left(\mathrm{V}_j^\mathcal{S},\mathrm{V}_j^\mathcal{T}\right)\in\mathbb{R}^L\)는 pixel-wise mean-square error를 표현하며, \(\left&lt;\cdot,\cdot\right&gt;\)은 inner product를 위한 Dirac notation이다. Supervised learning loss \(\mathcal{L}_{det}\)를 포함하는 전체 loss function은 아래와 같다.</p> \[\mathcal{L}_{total}=\mathcal{L}_{det} + \mathcal{L}_{aux}+\lambda\mathcal{L}_{distill}\] <p>여기서, \(\mathcal{L}_{det}\)와 \(\mathcal{L}_{distill}\)에 대한 gradient만 student network로 back-propagation되며 (student networks를 학습할 때 활용), \(\mathcal{L}_{aux}\)의 gradient는 instance-conditional decoding function \(\mathcal{G}\)과 auxiliary task와 관련된 modules만을 update한다.</p> <h2 id="conclusion">Conclusion</h2> <p>본 논문은 human observed instances와 연관된 knowledge를 찾고 선택하기 위한 instance-feature cross attention를 활용하는 Instance-Conditional knowledge Distillation (ICD)를 제안했다. 본 방법은 instance를 query로, teacher’s representation을 key로 encode하며, knowledge를 찾는 방법을 decoder에게 학습하기 위해, auxiliary task를 설계했다. 제안된 방법은 다양한 detectors에 대해 일관되게 성능을 향상시켰으며, 몇몇 student networks는 teacher networks보다 성능이 뛰어났다.</p> </div> </article> </div> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 SeongHak KIM. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-QZ6W7M2HLM"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-QZ6W7M2HLM");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>